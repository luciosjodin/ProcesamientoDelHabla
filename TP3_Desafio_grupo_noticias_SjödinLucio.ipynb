{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luciosjodin/ProcesamientoDelHabla/blob/master/TP3_Desafio_grupo_noticias_Sj%C3%B6dinLucio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TP3-Procesamiento del Habla\n",
        "##Sjödin Lucio"
      ],
      "metadata": {
        "id": "-oiUnma2zpkD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq6j8LsYq1Dr"
      },
      "source": [
        "### Vectorización de texto y modelo de clasificación Naïve Bayes con el dataset 20 newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l7cXR6CI30ry"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 20newsgroups por ser un dataset clásico de NLP ya viene incluido y formateado\n",
        "# en sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD-pVDWV_rQc"
      },
      "source": [
        "## Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ech9qJaUo9vK"
      },
      "outputs": [],
      "source": [
        "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxjSI7su_uWI"
      },
      "source": [
        "## Vectorización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-94VP0QYCzDn"
      },
      "outputs": [],
      "source": [
        "# instanciamos un vectorizador\n",
        "# ver diferentes parámetros de instanciación en la documentación de sklearn\n",
        "tfidfvect = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "ftPlyanuak8n",
        "outputId": "c82d024b-66da-40a8-e569-49538d1fac94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"A fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# en el atributo `data` accedemos al texto\n",
        "newsgroups_train.data[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1zxcXV6aC_oL"
      },
      "outputs": [],
      "source": [
        "# con la interfaz habitual de sklearn podemos fitear el vectorizador\n",
        "# (obtener el vocabulario y calcular el vector IDF)\n",
        "# y transformar directamente los datos\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "# `X_train` la podemos denominar como la matriz documento-término"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sv7TXbda41-",
        "outputId": "54ab6459-b0ca-48e8-adf3-bf8338be6fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "shape: (11314, 101631)\n",
            "cantidad de documentos: 11314\n",
            "tamaño del vocabulario (dimensionalidad de los vectores): 101631\n"
          ]
        }
      ],
      "source": [
        "# recordar que las vectorizaciones por conteos son esparsas\n",
        "# por ello sklearn convenientemente devuelve los vectores de documentos\n",
        "# como matrices esparsas\n",
        "print(type(X_train))\n",
        "print(f'shape: {X_train.shape}')\n",
        "print(f'cantidad de documentos: {X_train.shape[0]}')\n",
        "print(f'tamaño del vocabulario (dimensionalidad de los vectores): {X_train.shape[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgydNTZ2pAgR",
        "outputId": "a9c4ca15-5f74-4cd5-e6de-289374d8b464"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25775"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# una vez ajustado el vectorizador, podemos acceder a atributos como el vocabulario\n",
        "# aprendido. Es un diccionario que va de términos a índices.\n",
        "# El índice es la posición en el vector de documento.\n",
        "tfidfvect.vocabulary_['car']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xnTSZuvyrTcP"
      },
      "outputs": [],
      "source": [
        "# es muy útil tener el diccionario opuesto que va de índices a términos\n",
        "idx2word = {v: k for k,v in tfidfvect.vocabulary_.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swa-AgWrMSHM",
        "outputId": "e4246b92-b01c-4658-da49-c2b2a023f17e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# en `y_train` guardamos los targets que son enteros\n",
        "y_train = newsgroups_train.target\n",
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je5kxvQMDLvf",
        "outputId": "68ce977a-26b7-4c17-9479-5d09ba50ba6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clases [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# hay 20 clases correspondientes a los 20 grupos de noticias\n",
        "print(f'clases {np.unique(newsgroups_test.target)}')\n",
        "newsgroups_test.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXCICFSd_y90"
      },
      "source": [
        "## Similaridad de documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pki_olShnyE",
        "outputId": "c3e50ffe-13da-4e7a-8e76-8073d71041d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "/(hudson)\n",
            "/If someone inflicts pain on themselves, whether they enjoy it or not, they\n",
            "/are hurting themselves.  They may be permanently damaging their body.\n",
            "\n",
            "That is true.  It is also none of your business.  \n",
            "\n",
            "Some people may also reason that by reading the bible and being a Xtian\n",
            "you are permanently damaging your brain.  By your logic, it would be OK\n",
            "for them to come into your home, take away your bible, and send you off\n",
            "to \"re-education camps\" to save your mind from ruin.  Are you ready for\n",
            "that?  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "/(hudson)\n",
            "/And why is there nothing wrong with it?  Because you say so?  Who gave you\n",
            "/the authority to say that, and set the standard for morality?\n",
            "\n",
            "Why?\n",
            "\n",
            "Because: \n",
            "I am a living, thinking person able to make choices for myself.\n",
            "I do not \"need\" you to show me what you think is the way; I have observed\n",
            "too many errors in your thinking already to trust you to make up the\n",
            "rules for me.\n",
            "\n",
            "Because:\n",
            "I set the standard for my *own* morality, and I permit you to do \n",
            "the same for yourself.  I also do not try to force you to accept my rules.\n",
            "\n",
            "Because:\n",
            "Simply because you don't like what other people are doing doesn't give you\n",
            "the right to stop it, Hudson.  We are all aware that you would like for \n",
            "everyone to be like you.  However, it is obnoxious, arrogant thinking like \n",
            "yours, the \"I-know-I'm-morally-right-so-I-can-force-it-on-you\" bullshit \n",
            "that has brought us religious wars, pogroms against Jews, gay-bashing,\n",
            "and other atrocities by other people who, like you, \"knew\" they were\n",
            "morally right.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "(me)\n",
            "\n",
            "/(hudson)\n",
            "/Aren't you?  Aren't you indicating that I should not tell other people what\n",
            "to do?  Aren't you telling me it is wrong for me to do that? \n",
            "\n",
            "It is not a moral standard that I am presenting you with, Hudson.  It is\n",
            "a key to getting along in life with other people.  It is also a point of\n",
            "respect:  I trust other people to be intelligent enough to make their\n",
            "own choices, and I expect the same to be returned.  You, on the other\n",
            "hand, do not trust them, and want to make the choice for them--whether\n",
            "they like it or not.\n",
            "\n",
            "It is also a way to avoid an inconsistency:  if you believe that you have \n",
            "the right to set moral standards for others and interfere in their lives, \n",
            "then you must, by logic, admit that other people have the same right of \n",
            "interference in your life.  \n",
            "(Yes, I know; you will say that your religion is correct and tells you that\n",
            "only agents acting in behalf of your religion have the right of interference.\n",
            "However, other people will say that you have misinterpreted the Word of\n",
            "God and that *they* are the actual true believers, and that you are\n",
            "acting on your own authority.  And so it goes).\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "(hudson)\n",
            "/Who gave\n",
            "/you the authority to set such a moral standard for me to tell me that I \n",
            "/cannot set a moral standard for others?\n",
            "\n",
            "\n",
            "You can set all the standards that you want, actually.  But don't be surprised\n",
            "if people don't follow you like rats after the Pied Piper.  \n",
            "\n",
            "At the most basic form, I am not going to LET you tell me what to do;\n",
            "and if necessary, I will beat you to a bloody pulp before I let you actually\n",
            "interfere in my life.\n"
          ]
        }
      ],
      "source": [
        "# Veamos similaridad de documentos. Tomemos algún documento\n",
        "idx = 8754\n",
        "print(newsgroups_train.data[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ssa9bqJ-hA_v"
      },
      "outputs": [],
      "source": [
        "# midamos la similaridad coseno con todos los documentos de train\n",
        "cossim = cosine_similarity(X_train[idx], X_train)[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cossim"
      ],
      "metadata": {
        "id": "qQWdijV_-ClO",
        "outputId": "b5c8bea0-b9eb-439f-c234-ca01e4cffc89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.11252759, 0.09561582, 0.17267024, ..., 0.09162675, 0.1121114 ,\n",
              "       0.03334953])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_mDA7p3AzcQ",
        "outputId": "c9e08455-1dda-4949-ebf6-120cc3076869"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.49040531, 0.48118373, ..., 0.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# podemos ver los valores de similaridad ordenados de mayor a menos\n",
        "np.sort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OIhDA1jAryX",
        "outputId": "7cc27a3d-b67a-4b62-8c9e-003ca83db6db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8754,  6552, 10613, ...,  6988,  6980,  9520])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# y a qué documentos corresponden\n",
        "np.argsort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "hP7qLS4ZBLps"
      },
      "outputs": [],
      "source": [
        "# los 5 documentos más similares:\n",
        "mostsim = np.argsort(cossim)[::-1][1:6]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mostsim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1SFEyIIKBOI",
        "outputId": "0d39f9f9-78b4-40a7-883a-c582203c54c8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6552, 10613,  3616,  8726,  3902])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QdJLHPJACvaj",
        "outputId": "e97b3605-cd70-4086-da36-779c4796c0de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'talk.religion.misc'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# el documento original pertenece a la clase:\n",
        "newsgroups_train.target_names[y_train[idx]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWy_73epCbFG",
        "outputId": "a22d4211-d536-456a-f21e-2ead81f5ef9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "talk.religion.misc\n",
            "talk.religion.misc\n",
            "talk.religion.misc\n",
            "talk.politics.mideast\n",
            "talk.religion.misc\n"
          ]
        }
      ],
      "source": [
        "# y los 5 más similares son de las clases:\n",
        "for i in mostsim:\n",
        "  print(newsgroups_train.target_names[y_train[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRoNnKwhBqzq"
      },
      "source": [
        "### Modelo de clasificación Naïve Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "TPM0thDaLk0R",
        "outputId": "3f4dd567-df10-4d3f-8d00-bb0055760311"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# es muy fácil instanciar un modelo de clasificación Naïve Bayes y entrenarlo con sklearn\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NrQjzM48Mu4T"
      },
      "outputs": [],
      "source": [
        "# con nuestro vectorizador ya fiteado en train, vectorizamos los textos\n",
        "# del conjunto de test\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_test = newsgroups_test.target\n",
        "y_pred =  clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkGJhetEPdA4",
        "outputId": "491a1887-dc05-4fcd-82a7-5ef99c2ce806"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5854345727938506"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# el F1-score es una metrica adecuada para reportar desempeño de modelos de claificación\n",
        "# es robusta al desbalance de clases. El promediado 'macro' es el promedio de los\n",
        "# F1-score de cada clase. El promedio 'micro' es equivalente a la accuracy que no\n",
        "# es una buena métrica cuando los datasets son desbalanceados\n",
        "f1_score(y_test, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McArD4rSDR2K"
      },
      "source": [
        "### Consigna del desafío\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJgf6GQIIEH1"
      },
      "source": [
        "#**1**.\n",
        "\n",
        " Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
        "Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido\n",
        "la similaridad según el contenido del texto y la etiqueta de clasificación.\n",
        "\n",
        "**No puedes usar la misma solución ya presentada por alguien en el foro antes que Ud. Es decir, sus 5 documentos al azar deben ser diferentes a los ya presentados, o las palabras que elija para el ejercicio 3 deben ser diferentes a las ya presentadas.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dqFwQL_iW81Y"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Carga de datos (train/test)**"
      ],
      "metadata": {
        "id": "pVWr6YdHy0SF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ],
      "metadata": {
        "id": "_1vcvi_cYWoo"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Vectorización**"
      ],
      "metadata": {
        "id": "AiQ6KRIwy-Ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciamos un vectorizador\n",
        "tfidfvect = TfidfVectorizer(stop_words='english') #Eliminamos las stopwords en inglés"
      ],
      "metadata": {
        "id": "JPvkWtUM1RRZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformamos los datos en una matriz tf-idf\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data) # Matriz documento-término\n",
        "\n",
        "# Vectorizamos los textos del conjunto de test\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "\n",
        "# Guardamos los targets que son enteros (etiquetas numéricas de clases)\n",
        "y_train = newsgroups_train.target\n",
        "\n",
        "#Y también los targets del conjunto de test\n",
        "y_test = newsgroups_test.target\n"
      ],
      "metadata": {
        "id": "C6-4BOrO1Ul3"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prints Train\n",
        "\n",
        "print(type(X_train))\n",
        "print(f'Forma de la matriz (train): {X_train.shape}')\n",
        "print(f'Cantidad de documentos: {X_train.shape[0]}')\n",
        "print(f'Tamaño del vocabulario (dimensionalidad de los vectores): {X_train.shape[1]}')\n",
        "print(\"=\"*100)\n",
        "\n",
        "# Prints Test\n",
        "print(type(X_test))\n",
        "print(f'Forma de la matriz (test): {X_test.shape}')\n",
        "print(f'cantidad de documentos: {X_test.shape[0]}')\n",
        "print(f'tamaño del vocabulario (dimensionalidad de los vectores): {X_test.shape[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YG0iejB2NcH",
        "outputId": "4f2b56e4-bf11-40e1-a406-e31b51b58d84"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "Forma de la matriz (train): (11314, 101322)\n",
            "Cantidad de documentos: 11314\n",
            "Tamaño del vocabulario (dimensionalidad de los vectores): 101322\n",
            "====================================================================================================\n",
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "Forma de la matriz (test): (7532, 101322)\n",
            "cantidad de documentos: 7532\n",
            "tamaño del vocabulario (dimensionalidad de los vectores): 101322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Similaridad de Documentos**"
      ],
      "metadata": {
        "id": "KpaOE6cqzDQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selección de la semilla (random) para garantizar que las selecciones aleatorias de numpy sean reproducibles\n",
        "np.random.seed(66)\n",
        "\n",
        "# Selección de los 5 documentos aleatorios\n",
        "documentos = np.random.choice(X_train.shape[0], size=5, replace=False)\n",
        "\n",
        "print(f\"Los documentos seleccionados son (id): {documentos}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2RH8Pfb287K",
        "outputId": "5d335227-4598-446c-8b34-1b80b16e1af4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los documentos seleccionados son (id): [2600 7908 7244 6444 7288]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iteración sobre los documentos\n",
        "for id in documentos:\n",
        "  print(\"=\" * 100)\n",
        "  print(f\"Documento original (ID: {id}):\")\n",
        "  print(\"Clase del documento original:\", newsgroups_train.target_names[y_train[id]])\n",
        "  print(f'Extracto: {newsgroups_train.data[id][:300]} ...')\n",
        "  print(\"=\" * 100)\n",
        "\n",
        "  # Similaridad Coseno\n",
        "  cossim = cosine_similarity(X_train[id], X_train)[0]\n",
        "\n",
        "  # Encontramos los 5 documentos más similares:\n",
        "  mostsim = np.argsort(cossim)[::-1][1:6]\n",
        "\n",
        "  # el documento original pertenece a la clase:\n",
        "  newsgroups_train.target_names[y_train[id]]\n",
        "\n",
        "  # y los 5 más similares son de las clases:\n",
        "  for i, id_similar in enumerate(mostsim):\n",
        "    print(f\"\\nDocumento similar N°{i+1} (ID: {id_similar}, Similaridad: {cossim[id_similar]:.4f}):\")\n",
        "    print(\"Clase del documento similar:\", newsgroups_train.target_names[y_train[id_similar]])\n",
        "    print(f'Extracto: {newsgroups_train.data[id_similar][:300]} ...')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz46tmOO3Tp2",
        "outputId": "365eaec1-2377-45ed-df65-1349cdff0e0f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "Documento original (ID: 2600):\n",
            "Clase del documento original: alt.atheism\n",
            "Extracto: \n",
            "\n",
            "Anyone who dies for a \"cause\" runs the risk of dying for a lie.  As for\n",
            "people being able to tell if he was a liar, well, we've had grifters and\n",
            "charlatans since the beginning of civilization.  If David Copperfield had\n",
            "been the Messiah, I bet he could have found plenty of believers.  \n",
            "Jesus was ha ...\n",
            "====================================================================================================\n",
            "\n",
            "Documento similar N°1 (ID: 10571, Similaridad: 0.1915):\n",
            "Clase del documento similar: talk.religion.misc\n",
            "Extracto: : I will clarify my earlier quote.  God's laws were originally written for \n",
            ": the Israelites.  Jesus changed that fact by now making the Law applicable to\n",
            ": all people, not just the Jews.  Gentiles could be part of the kingdom of\n",
            ": Heaven through the saving grace of God.  I never said that the Law w ...\n",
            "\n",
            "Documento similar N°2 (ID: 3998, Similaridad: 0.1800):\n",
            "Clase del documento similar: alt.atheism\n",
            "Extracto: ->\tFirst I want to start right out and say that I'm a Christian.  It \n",
            "->makes sense to be one.  Have any of you read Tony Campollo's book- liar, \n",
            "->lunatic, or the real thing?  (I might be a little off on the title, but he \n",
            "->writes the book.  Anyway he was part of an effort to destroy Christianity, ...\n",
            "\n",
            "Documento similar N°3 (ID: 2113, Similaridad: 0.1743):\n",
            "Clase del documento similar: alt.atheism\n",
            "Extracto: \n",
            "(WEBSTER:  myth:  \"a traditional or legendary story...\n",
            "           ...a belief...whose truth is accepted uncritically.\")\n",
            "\n",
            "How does that qualify?\n",
            "Indeed, it's almost oxymoronic...a rather amusing instance.\n",
            "I've found that most atheists hold almost no atheist-views as\n",
            "\"accepted uncritically,\" especial ...\n",
            "\n",
            "Documento similar N°4 (ID: 2765, Similaridad: 0.1733):\n",
            "Clase del documento similar: soc.religion.christian\n",
            "Extracto: Hi,\n",
            "\n",
            "I don't know much about Bible. Could you tell me the relations of\n",
            "Christians with non-Christians in Bible? How should be The relations of\n",
            "christian nations with each other and the relations of Christian nations\n",
            "with other nations who are not Christians?\n",
            "\n",
            "The other question is about the concept  ...\n",
            "\n",
            "Documento similar N°5 (ID: 2322, Similaridad: 0.1674):\n",
            "Clase del documento similar: alt.atheism\n",
            "Extracto: \n",
            "\n",
            "Or he was just convinced by religious fantasies of the time that he was the\n",
            "Messiah, or he was just some rebel leader that an organisation of Jews built\n",
            "into Godhood for the purpose off throwing of the yoke of Roman oppression,\n",
            "or.......\n",
            "\n",
            "\n",
            "Are the Moslem fanatics who strap bombs to their backs and ...\n",
            "====================================================================================================\n",
            "Documento original (ID: 7908):\n",
            "Clase del documento original: talk.politics.guns\n",
            "Extracto: \n",
            "Did you forget to put in a sarcasm flag? ...\n",
            "====================================================================================================\n",
            "\n",
            "Documento similar N°1 (ID: 7686, Similaridad: 0.2973):\n",
            "Clase del documento similar: rec.sport.baseball\n",
            "Extracto: \n",
            "I think the next time I post something like this, I obviously need to make\n",
            "the sarcasm a bit more obvious...\n",
            "\n",
            "\n",
            "chuck\n",
            " ...\n",
            "\n",
            "Documento similar N°2 (ID: 9551, Similaridad: 0.2534):\n",
            "Clase del documento similar: rec.sport.baseball\n",
            "Extracto:  [Most of tirade deleted .. I have an editor and know how to use it] \n",
            "\n",
            "  Either this is an example of *great* sarcasm or I'm really, really worried.\n",
            " ...\n",
            "\n",
            "Documento similar N°3 (ID: 1703, Similaridad: 0.2139):\n",
            "Clase del documento similar: talk.religion.misc\n",
            "Extracto: RE: Red, wwhite, and black, the colors of the Imperial German war-flag -- ...\n",
            "\n",
            "Documento similar N°4 (ID: 2889, Similaridad: 0.2032):\n",
            "Clase del documento similar: talk.politics.misc\n",
            "Extracto: \n",
            "I'll answer you're sarcasm with more sarcasm:\n",
            "\n",
            "\tBoy, it looks like the WOD is WORKING REALLY GOOD to stop people from\n",
            "\tbeing screwed up in the head, given that example!\n",
            "\n",
            "(Issue: your friend _got_ his drugs--legal or not legal, he'll continue to\n",
            "get them.  Issue #2: why should _I_, as somebody who d ...\n",
            "\n",
            "Documento similar N°5 (ID: 4033, Similaridad: 0.1892):\n",
            "Clase del documento similar: talk.politics.mideast\n",
            "Extracto: Boy that was really humorous.  I'm impressed by your incredible senses of wit,\n",
            "sarcasm and propriety.  Mind if I post jokes about your mother?\n",
            " ...\n",
            "====================================================================================================\n",
            "Documento original (ID: 7244):\n",
            "Clase del documento original: rec.motorcycles\n",
            "Extracto: \n",
            "\n",
            "No, I don't watch that Bu**Sh*t.\n",
            "\n",
            "\n",
            "So, does this mean the cop is at fault for rear-ending the bike?  You know,\n",
            "following too closely and reckless driving?\n",
            " ...\n",
            "====================================================================================================\n",
            "\n",
            "Documento similar N°1 (ID: 2294, Similaridad: 0.1739):\n",
            "Clase del documento similar: rec.motorcycles\n",
            "Extracto: If I have one thing to say about \"No Fault\" it would be\n",
            "\"It isn't\" ...\n",
            "\n",
            "Documento similar N°2 (ID: 10480, Similaridad: 0.1722):\n",
            "Clase del documento similar: sci.med\n",
            "Extracto: \n",
            "\n",
            "does anyone know?\n",
            "\n",
            "--  ...\n",
            "\n",
            "Documento similar N°3 (ID: 11064, Similaridad: 0.1624):\n",
            "Clase del documento similar: rec.motorcycles\n",
            "Extracto: & Can somebody tell me what all the letter spesifications on motorcycle models \n",
            "& really mean. \n",
            "& Example: What means the C, the B and the R in Honda CBR. - Or the V, S, G, L \n",
            "& and P in Suzuki VS750GLP\n",
            "\n",
            "Honda:  a \"V\" designates a V engine street bike. \"VF\" for V-4, \"VT\" for V-twin.\n",
            "\"CB\" is a street ...\n",
            "\n",
            "Documento similar N°4 (ID: 8467, Similaridad: 0.1556):\n",
            "Clase del documento similar: rec.motorcycles\n",
            "Extracto: \n",
            "1) The next time you get stoped by a cop, never never never admit to anything.\n",
            "\n",
            "2) Don't volunteer any information.\n",
            "\n",
            "3) When a retoracle question is ask by the cop, like \"...it <looked> like you were going kinda fast coming down highway 12.  You <must have> been going at least 70 or 75?\" -- the cor ...\n",
            "\n",
            "Documento similar N°5 (ID: 3769, Similaridad: 0.1487):\n",
            "Clase del documento similar: rec.sport.baseball\n",
            "Extracto: : \t\t\tWatch us soar in 1993!\n",
            "\n",
            "\n",
            "Shouldn't that be 'Watch us stoned in 1993!'? :)\n",
            "\n",
            "or maybe 'Watch us suck in 1993!'\n",
            "\n",
            "or even 'Watch us sore in 1993!' ...\n",
            "====================================================================================================\n",
            "Documento original (ID: 6444):\n",
            "Clase del documento original: rec.sport.baseball\n",
            "Extracto: Having run completely out of time, I've got to get my prophesies and\n",
            "predictions for the A.L. out.  Qualifications -- one of the worse\n",
            "finishes in last year's prediction contest.\n",
            "\n",
            "AL East -- 1993\n",
            "\n",
            "1.  Baltimore Orioles\n",
            "Why the Orioles?  Well, I pondered long and hard, and it all came down to\n",
            "this:\n",
            "  ...\n",
            "====================================================================================================\n",
            "\n",
            "Documento similar N°1 (ID: 3885, Similaridad: 0.2756):\n",
            "Clase del documento similar: alt.atheism\n",
            "Extracto: I'm sold!  Where do I sign up?\n",
            " ...\n",
            "\n",
            "Documento similar N°2 (ID: 3909, Similaridad: 0.2302):\n",
            "Clase del documento similar: rec.sport.baseball\n",
            "Extracto: I thought I'd post my predicted standings since I find those posted by others\n",
            "to be interesting.  Sorry this is after Opening Day.  I certify that these\n",
            "were completed before the first pitch. :-)\n",
            "\n",
            "AL East\n",
            "1.  New York Yankees - the most (only?) improved team in this division\n",
            "2.  Toronto Blue Jays -  ...\n",
            "\n",
            "Documento similar N°3 (ID: 6133, Similaridad: 0.2105):\n",
            "Clase del documento similar: rec.sport.baseball\n",
            "Extracto: Is there any doubt that this is true?  After a few down years, the A.L. East\n",
            "is back to where it was in the early eighties.  With the emergence of the O's\n",
            "and the Yanks, it is far and away the best.  While the N.L. West has the best\n",
            "team in baseball, and the Reds aren't bad either, they have nothing ...\n",
            "\n",
            "Documento similar N°4 (ID: 6147, Similaridad: 0.1995):\n",
            "Clase del documento similar: rec.sport.baseball\n",
            "Extracto: Oops!  I came across this file from last year.  Thought you might\n",
            "enjoy some of these thoughts.  The predictions were made on the\n",
            "date indicated.  They are largely out of order.\n",
            "\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "June 11, 1992\n",
            "tedward@cs.cornell.edu (ME! ...\n",
            "\n",
            "Documento similar N°5 (ID: 6248, Similaridad: 0.1988):\n",
            "Clase del documento similar: sci.electronics\n",
            "Extracto: \n",
            "\n",
            "In the past I've managed to buy used neon sign transformers from sign shops \n",
            "for about $20. Try calling around.\n",
            " ...\n",
            "====================================================================================================\n",
            "Documento original (ID: 7288):\n",
            "Clase del documento original: talk.politics.mideast\n",
            "Extracto: \n",
            "\n",
            "I always like your kind of odds. The Greek governments must be held \n",
            "to account for the sub-human conditions of the Turkish minority living \n",
            "in the Western Thrace under the brutal Greek domination. The religious \n",
            "persecution, cultural oppression and economical ex-communication applied \n",
            "to the Turk ...\n",
            "====================================================================================================\n",
            "\n",
            "Documento similar N°1 (ID: 8081, Similaridad: 0.2735):\n",
            "Clase del documento similar: talk.politics.mideast\n",
            "Extracto: \n",
            "\n",
            "And the 'Turkish Karabag' is next. As for 'Cyprus', In 1974, Turkiye \n",
            "stepped into Cyprus to preserve the lives of the Turkish population \n",
            "there. This is nothing but a simple historical fact. Unfortunately, \n",
            "the intervention was too late at least for some of the victims. Mass \n",
            "graves containing nu ...\n",
            "\n",
            "Documento similar N°2 (ID: 10765, Similaridad: 0.2731):\n",
            "Clase del documento similar: talk.politics.mideast\n",
            "Extracto: \n",
            "\n",
            "Pardon me?\n",
            "\n",
            "\"Greece Government Rail-Roads Two Turkish Ethnic Deputies\"\n",
            "\n",
            "While World Human Rights Organizations Scream, Greeks \n",
            "Persistently Work on Removing the Parliamentary Immunity\n",
            "of Dr. Sadik Ahmet and Mr. Ahmet Faikoglu.\n",
            "\n",
            "\n",
            "Dr. Sadik Ahmet, Turkish Ethnic Member of Greek Parliament, Visits US ...\n",
            "\n",
            "Documento similar N°3 (ID: 10328, Similaridad: 0.2583):\n",
            "Clase del documento similar: talk.politics.mideast\n",
            "Extracto: \n",
            "\n",
            "\n",
            "\n",
            "Are you related to 'Arromdian' of ASALA/SDPA/ARF Terrorism and Revisionism \n",
            "Triangle?\n",
            "\n",
            "\n",
            "Ditto.\n",
            "\n",
            "\n",
            "HELSINKI WATCH: \"PROBLEMS OF TURKS IN WESTERN THRACE CONTINUE\"\n",
            "\n",
            "Ankara (A.A)  In a 15-page report  of the \"Helsinki Watch\"  it is\n",
            "stated that the Turkish minority in Western Thrace is still faced\n",
            "wit ...\n",
            "\n",
            "Documento similar N°4 (ID: 503, Similaridad: 0.2327):\n",
            "Clase del documento similar: talk.politics.mideast\n",
            "Extracto: \n",
            "\n",
            "Dr. Goebels thought that a lie repeated enough times could finally \n",
            "be believed. I have been observing that 'Poly' has been practicing \n",
            "Goebels' rule quite loyally. 'Poly's audience is mostly made of Greeks \n",
            "who are not allowed to listen to Turkish news. However, in today's \n",
            "informed world Greek p ...\n",
            "\n",
            "Documento similar N°5 (ID: 2672, Similaridad: 0.2093):\n",
            "Clase del documento similar: talk.politics.mideast\n",
            "Extracto: \n",
            "\n",
            "Let's face it, if the words don't get into your noggin in the first place, \n",
            "there's no hope. Now tell us, 'SDPA.ORG', a mouthpiece of the fascist x-Soviet \n",
            "Armenian Government: what was your role in the murder of Orhan Gunduz and \n",
            "Kemal Arikan? How many more Muslims will be slaughtered by 'SDPA.OR ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ecf6bd7"
      },
      "source": [
        "##**Análisis Similaridad de Documentos**\n",
        "\n",
        "Se seleccionaron 5 documentos al azar del conjunto de entrenamiento para medir su similaridad coseno con el resto de los documentos del conjunto. Veamos cada caso:\n",
        "\n",
        "**Documento Original (id 2600):**\n",
        "*   **Clase:** `alt.atheism`\n",
        "\n",
        "Los 5 documentos más similares, con similaridades entre 0.1674 y 0.1915, provienen en su mayoría de las clases `alt.atheism` y `talk.religion.misc`. Esto claro que tiene sentido, ya que estos grupos de noticias a menudo contienen discusiones relacionadas justamente con el ateísmo, la religión y muchas veces abren debates sobre creencias y cuestiones de fé. La similaridad, aunque no es muy alta en términos absolutos, parece capturar la temática que comparten estos documentos y el original.\n",
        "\n",
        "**Documento Original (id 7908):**\n",
        "*   **Clase:** `talk.politics.guns`\n",
        "\n",
        "Los documentos más similares tienen similaridades entre 0.1892 y 0.2973. En este caso es interesante notar que, si bien hay documentos similares de las clases `talk.politics.misc` y `talk.politics.mideast` (básicamente política), también hay documentos similares de `rec.sport.baseball` y `talk.religion.misc`. La previsualización de estos documentos similares (extractos) a contienen comentarios sobre \"sarcasmo\". Esto sugiere que la similaridad en este caso podría estar influenciada por el estilo o el tono del texto (el uso del sarcasmo por ejemplo).\n",
        "\n",
        "**Documento Original (id 7244):**\n",
        "*   **Clase:** `rec.motorcycles`\n",
        "\n",
        "Los documentos más similares presentan similaridades de entre 0.1487 y 0.1739. La mayoría de estos documentos similares provienen de la clase `rec.motorcycles`, lo cual es coherente con la clase del documento original (misma clase). Sin embargo, también aparece un documento de `sci.med` y otro de `rec.sport.baseball`. Las similaridades son relativamente bajas, lo que podría indicar que el documento original es algo único dentro de su clase o que la similaridad encontrada consiste en el uso compatido de algunos términos clave que fueron determinantes.\n",
        "\n",
        "**Documento Original (id 6444):**\n",
        "*   **Clase:** `rec.sport.baseball`\n",
        "\n",
        "Los documentos más similares tienen similaridades entre 0.1988 y 0.2756. La mayoría de los documentos similares pertenecen a la clase `rec.sport.baseball`, lo cual es lo esperado. Sin embargo, otra vez, aparece ahora un documento de `alt.atheism` y otro de `sci.electronics`. Esto podría deberse a que estos documentos comparten términos (como el caso anterior) o frases comunes que no son exclusivos del baseball, o a que el documento original toca otros temas.\n",
        "\n",
        "**Documento Original (id 7288):**\n",
        "*   **Clase:** `talk.politics.mideast`\n",
        "\n",
        "Los documentos más similares tienen similaridades entre 0.2731 y 0.2735. Los 5 documentos más similares provienen de la clase `talk.politics.mideast`. Las similaridades son un poco más altas si las comparamos con los otros casos, lo que sugiere que este documento tiene un conjunto de términos y un contexto temático muy específico y recurrente dentro de su grupo de noticias."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Conclusión:**\n",
        "\n",
        "La similaridad coseno basada en la vectorización TF-IDF parece capturar la similitud temática entre documentos, pero también puede verse influenciada por el estilo de escritura, el uso de términos específicos o la tenencia también de términos menos específicos de la clase del documento. De todos modos, en la mayoría de los casos, los documentos más similares tienden a pertenecer a la misma clase que el documento original o a clases temáticamente relacionadas. Sin embargo, la aparición de documentos de clases no relacionadas resalta los desafíos de la similaridad puramente basada en términos y la posibilidad de que términos o frases compartidas puedan generar similaridad incluso entre documentos de diferentes temáticas."
      ],
      "metadata": {
        "id": "xIFNuvD68RfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2**.\n",
        " Transponer la matriz documento-término. De esa manera se obtiene una matriz\n",
        "término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
        "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares. **La elección de palabras no debe ser al azar para evitar la aparición de términos poco interpretables, elegirlas \"manualmente\"**."
      ],
      "metadata": {
        "id": "JS1u_5kle7U8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matriz Término-Documento/Similaridad de Palabras"
      ],
      "metadata": {
        "id": "vA1F_pvPzbCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transposición de la matriz documento-término para obtener la matriz término-documento\n",
        "X_train_T = X_train.T\n",
        "\n",
        "# Elección \"manual\" de las palabras\n",
        "palabras = ['internet', 'government', 'religion', 'artificial', 'human']\n",
        "\n",
        "# Obtención de los índices de las palabras seleccionadas en el vocabulario\n",
        "id_palabras = [tfidfvect.vocabulary_[word] for word in palabras if word in tfidfvect.vocabulary_]\n",
        "\n",
        "# Iteración sobre las palabras seleccionadas y búsqueda de sus palabras más similares\n",
        "for word_id in id_palabras:\n",
        "    word = tfidfvect.get_feature_names_out()[word_id]\n",
        "    print(\"=\" * 100)\n",
        "    print(f\"Palabra original: {word}\")\n",
        "\n",
        "    # Similaridad Coseno de la palabra con todas las demás palabras\n",
        "    word_cossim = cosine_similarity(X_train_T[word_id], X_train_T)[0]\n",
        "\n",
        "    # Obtención de los índices de las palabras más similares (excluyendo la palabra original)\n",
        "    most_similar_word_indices = np.argsort(word_cossim)[::-1][1:6]\n",
        "\n",
        "    # Itero e imprimo cada palabra similar\n",
        "    for i, sim_word_idx in enumerate(most_similar_word_indices):\n",
        "        sim_word = tfidfvect.get_feature_names_out()[sim_word_idx]\n",
        "        print(f\"Similar {i+1}: {sim_word} (similaridad: {word_cossim[sim_word_idx]:.4f})\")"
      ],
      "metadata": {
        "id": "DmfG6DCYW9Kt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64dd6cf3-0585-4137-a94d-f70a254a28d9"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "Palabra original: internet\n",
            "Similar 1: originations (similaridad: 0.2574)\n",
            "Similar 2: umask (similaridad: 0.2574)\n",
            "Similar 3: influencing (similaridad: 0.2574)\n",
            "Similar 4: chfn (similaridad: 0.2574)\n",
            "Similar 5: constrained (similaridad: 0.2553)\n",
            "====================================================================================================\n",
            "Palabra original: government\n",
            "Similar 1: libertarian (similaridad: 0.2319)\n",
            "Similar 2: encryption (similaridad: 0.2264)\n",
            "Similar 3: agencies (similaridad: 0.2047)\n",
            "Similar 4: regulation (similaridad: 0.2020)\n",
            "Similar 5: people (similaridad: 0.2016)\n",
            "====================================================================================================\n",
            "Palabra original: religion\n",
            "Similar 1: religious (similaridad: 0.2628)\n",
            "Similar 2: religions (similaridad: 0.2254)\n",
            "Similar 3: purpsoe (similaridad: 0.2085)\n",
            "Similar 4: crusades (similaridad: 0.2032)\n",
            "Similar 5: categorized (similaridad: 0.2009)\n",
            "====================================================================================================\n",
            "Palabra original: artificial\n",
            "Similar 1: aftereffects (similaridad: 0.4421)\n",
            "Similar 2: hyperactivity (similaridad: 0.4373)\n",
            "Similar 3: aggressively (similaridad: 0.3858)\n",
            "Similar 4: flavoring (similaridad: 0.3830)\n",
            "Similar 5: extracted (similaridad: 0.3602)\n",
            "====================================================================================================\n",
            "Palabra original: human\n",
            "Similar 1: beings (similaridad: 0.2476)\n",
            "Similar 2: wsidom (similaridad: 0.2288)\n",
            "Similar 3: davar (similaridad: 0.2288)\n",
            "Similar 4: adressed (similaridad: 0.2288)\n",
            "Similar 5: nestorianism (similaridad: 0.2264)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Análisis Similaridad de Palabras**\n",
        "\n",
        "* `'internet'`:\n",
        "\n",
        "Las palabras más similares (`'originations', 'umask', 'influencing', 'chfn', 'constrained'`) tienen similaridades bajas (alrededor de 0.25). Estas palabras no tienen una conexión semántica obvia con \"internet\". Esto sugiere que \"internet\" co-ocurre con una variedad de términos que pueden estar más relacionados con el uso técnico o aspectos específicos discutidos en los grupos de noticias (como \"umask\" y \"chfn\" que son términos técnicos e informáticos), en lugar de con sinónimos o términos conceptualmente más cercanos.\n",
        "\n",
        "* `'government'`:\n",
        "\n",
        "Las palabras más similares (`'libertarian', 'encryption', 'agencies', 'regulation', 'people'`) tienen similaridades entre 0.20 y 0.23. Como mencioné antes, estas palabras sí tienen una relación conceptual y contextual clara con \"government\". Esto refuerza la idea de que la similaridad coseno, cuando las palabras aparecen en contextos temáticos definidos, puede capturar relaciones significativas.\n",
        "\n",
        "* `'religion'`:\n",
        "\n",
        "Las palabras más similares (`'religious', 'religions', 'purpsoe', 'crusades', 'categorized'`) muestran similaridades de entre 0.20 y 0.26. La relación con \"religión\" es muy fuerte y directa para la mayoría de ellas, como se analizó previamente. La aparición de 'purpsoe' (posiblemente error tipográfico de 'purpose') y 'categorized' sugiere que las discusiones sobre religión en este dataset a menudo implican la categorización de creencias o la discusión de propósitos religiosos.\n",
        "\n",
        "* `'artificial'`:\n",
        "\n",
        "Las palabras más similares (`'aftereffects', 'hyperactivity', 'aggressively', 'flavoring', 'extracted'`) tienen similaridades notablemente más altas (entre 0.36 y 0.44) en comparación con las otras palabras. Esto sugiere que \"artificial\" tiene un contexto de uso más específico y recurrente en el dataset. Las palabras similares apuntan fuertemente a discusiones relacionadas con aditivos alimentarios, salud, y procesos (como extracción o manipulación), lo que probablemente proviene de los grupos de noticias relacionados con ciencia o medicina.\n",
        "\n",
        "* `'human'`:\n",
        "\n",
        "Las palabras más similares (`'beings', 'wsidom', 'davar', 'adressed', 'nestorianism'`) tienen similaridades bajas (alrededor de 0.22 a 0.24). \"Beings\" es semánticamente muy cercana a \"human\". Las otras palabras ('wsidom', 'davar', 'adressed', 'nestorianism') parecen menos relacionadas a primera vista. 'Nestorianism' es una rama del cristianismo, lo que podría vincularse a discusiones sobre la naturaleza humana en contextos religiosos. Las otras podrían ser errores tipográficos o términos muy específicos de algún subdominio."
      ],
      "metadata": {
        "id": "ZFIQ4-xVF1oC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusión:**\n",
        "\n",
        "La similaridad coseno basada en TF-IDF refleja la co-ocurrencia de palabras. Para términos que aparecen en contextos temáticos muy específicos y recurrentes (como 'artificial' en relación con aditivos o 'religion' y 'baseball' con sus términos asociados), la similaridad puede ser más alta y semánticamente interpretable. Para términos más generales o que aparecen en contextos más dispersos ('internet', 'human'), las similaridades pueden ser más bajas y las palabras similares menos relacionadas semánticamente, reflejando patrones de co-ocurrencia más sutiles o variados en el dataset."
      ],
      "metadata": {
        "id": "2zoFnXt-_-Vx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3hirpeJeMMa"
      },
      "source": [
        "#**3**.\n",
        " Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
        "(f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros\n",
        "de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial\n",
        "y ComplementNB."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo de clasificación Naïve Bayes"
      ],
      "metadata": {
        "id": "_FcBhlsbzUpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros para TfidfVectorizer\n",
        "param_grid_tfidf = {\n",
        "    'max_df': [0.95, 0.98],\n",
        "    'min_df': [2, 3],\n",
        "    'ngram_range': [(1, 1), (1, 2)],\n",
        "    # 'use_idf': [True, False] # Eliminamos use_idf según la solicitud\n",
        "}\n",
        "\n",
        "# Parámetros para los modelos Naïve Bayes\n",
        "param_grid_nb = {\n",
        "    'alpha': [0.1, 0.5, 1.0] # Incluimos el suavizado de Laplace (alpha)\n",
        "}       # alpha es un parámetro de suavizado de Laplace. Sirve para evitar probabilidades cero\n",
        "        # cuando una palabra que aparece en el test no estaba en el entrenamiento,\n",
        "        # sumando 'alpha' a los conteos de términos.\n",
        "\n",
        "# Inicialización de variables\n",
        "best_score = 0\n",
        "best_params_tfidf = {}\n",
        "best_params_nb = {}\n",
        "best_model = None\n",
        "\n",
        "# Iteraración sobre el grid de parámetros del vectorizador\n",
        "for params_tfidf in ParameterGrid(param_grid_tfidf):\n",
        "    print(f\"Probando parámetros del vectorizador: {params_tfidf}\")\n",
        "\n",
        "    # Instanciar TfidfVectorizer con los parámetros actuales\n",
        "    tfidfvect_tuned = TfidfVectorizer(**params_tfidf, stop_words='english')\n",
        "\n",
        "    # Ajustar el vectorizador a los datos de entrenamiento y transformar\n",
        "    X_train_tuned = tfidfvect_tuned.fit_transform(newsgroups_train.data)\n",
        "\n",
        "    # Transformar los datos de prueba\n",
        "    X_test_tuned = tfidfvect_tuned.transform(newsgroups_test.data)\n",
        "\n",
        "    # Iterar sobre el grid de parámetros de los modelos Naïve Bayes\n",
        "    for params_nb in ParameterGrid(param_grid_nb):\n",
        "        print(f\"  Probando parámetros del mdelo Naïve Bayes: {params_nb}\")\n",
        "\n",
        "        # Multinomial\n",
        "\n",
        "        clf_mnb = MultinomialNB(**params_nb)\n",
        "        clf_mnb.fit(X_train_tuned, y_train)\n",
        "        y_pred_mnb = clf_mnb.predict(X_test_tuned)\n",
        "        f1_macro_mnb = f1_score(y_test, y_pred_mnb, average='macro')\n",
        "\n",
        "        print(f\"    - MultinomialNB F1-score macro: {f1_macro_mnb:.4f}\")\n",
        "\n",
        "        if f1_macro_mnb > best_score:\n",
        "            best_score = f1_macro_mnb\n",
        "            best_params_tfidf = params_tfidf\n",
        "            best_params_nb = params_nb\n",
        "            best_model = 'MultinomialNB'\n",
        "\n",
        "        # ComplementNB\n",
        "        clf_cnb = ComplementNB(**params_nb)\n",
        "        clf_cnb.fit(X_train_tuned, y_train)\n",
        "        y_pred_cnb = clf_cnb.predict(X_test_tuned)\n",
        "        f1_macro_cnb = f1_score(y_test, y_pred_cnb, average='macro')\n",
        "\n",
        "        print(f\"    - ComplementNB F1-score macro: {f1_macro_cnb:.4f}\")\n",
        "\n",
        "        if f1_macro_cnb > best_score:\n",
        "            best_score = f1_macro_cnb\n",
        "            best_params_tfidf = params_tfidf\n",
        "            best_params_nb = params_nb\n",
        "            best_model = 'ComplementNB'\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(f\"Mejor F1-score macro obtenido: {best_score:.4f}\")\n",
        "print(f\"Mejores parámetros del vectorizador: {best_params_tfidf}\")\n",
        "print(f\"Mejores parámetros del modelo: {best_params_nb}\")\n",
        "print(f\"Mejor modelo: {best_model}\")"
      ],
      "metadata": {
        "id": "Kz-xKnmQXMXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4003fad-2332-4fca-a792-714e4289e98f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probando parámetros del vectorizador: {'max_df': 0.95, 'min_df': 2, 'ngram_range': (1, 1)}\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 0.1}\n",
            "    - MultinomialNB F1-score macro: 0.6798\n",
            "    - ComplementNB F1-score macro: 0.6887\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 0.5}\n",
            "    - MultinomialNB F1-score macro: 0.6626\n",
            "    - ComplementNB F1-score macro: 0.6974\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 1.0}\n",
            "    - MultinomialNB F1-score macro: 0.6512\n",
            "    - ComplementNB F1-score macro: 0.6943\n",
            "Probando parámetros del vectorizador: {'max_df': 0.95, 'min_df': 2, 'ngram_range': (1, 2)}\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 0.1}\n",
            "    - MultinomialNB F1-score macro: 0.6822\n",
            "    - ComplementNB F1-score macro: 0.7018\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 0.5}\n",
            "    - MultinomialNB F1-score macro: 0.6598\n",
            "    - ComplementNB F1-score macro: 0.7101\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 1.0}\n",
            "    - MultinomialNB F1-score macro: 0.6504\n",
            "    - ComplementNB F1-score macro: 0.7037\n",
            "Probando parámetros del vectorizador: {'max_df': 0.95, 'min_df': 3, 'ngram_range': (1, 1)}\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 0.1}\n",
            "    - MultinomialNB F1-score macro: 0.6818\n",
            "    - ComplementNB F1-score macro: 0.6822\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 0.5}\n",
            "    - MultinomialNB F1-score macro: 0.6642\n",
            "    - ComplementNB F1-score macro: 0.6921\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 1.0}\n",
            "    - MultinomialNB F1-score macro: 0.6530\n",
            "    - ComplementNB F1-score macro: 0.6916\n",
            "Probando parámetros del vectorizador: {'max_df': 0.95, 'min_df': 3, 'ngram_range': (1, 2)}\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 0.1}\n",
            "    - MultinomialNB F1-score macro: 0.6802\n",
            "    - ComplementNB F1-score macro: 0.6961\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 0.5}\n",
            "    - MultinomialNB F1-score macro: 0.6616\n",
            "    - ComplementNB F1-score macro: 0.7026\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 1.0}\n",
            "    - MultinomialNB F1-score macro: 0.6512\n",
            "    - ComplementNB F1-score macro: 0.6999\n",
            "Probando parámetros del vectorizador: {'max_df': 0.98, 'min_df': 2, 'ngram_range': (1, 1)}\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 0.1}\n",
            "    - MultinomialNB F1-score macro: 0.6798\n",
            "    - ComplementNB F1-score macro: 0.6887\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 0.5}\n",
            "    - MultinomialNB F1-score macro: 0.6626\n",
            "    - ComplementNB F1-score macro: 0.6974\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 1.0}\n",
            "    - MultinomialNB F1-score macro: 0.6512\n",
            "    - ComplementNB F1-score macro: 0.6943\n",
            "Probando parámetros del vectorizador: {'max_df': 0.98, 'min_df': 2, 'ngram_range': (1, 2)}\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 0.1}\n",
            "    - MultinomialNB F1-score macro: 0.6822\n",
            "    - ComplementNB F1-score macro: 0.7018\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 0.5}\n",
            "    - MultinomialNB F1-score macro: 0.6598\n",
            "    - ComplementNB F1-score macro: 0.7101\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 1.0}\n",
            "    - MultinomialNB F1-score macro: 0.6504\n",
            "    - ComplementNB F1-score macro: 0.7037\n",
            "Probando parámetros del vectorizador: {'max_df': 0.98, 'min_df': 3, 'ngram_range': (1, 1)}\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 0.1}\n",
            "    - MultinomialNB F1-score macro: 0.6818\n",
            "    - ComplementNB F1-score macro: 0.6822\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 0.5}\n",
            "    - MultinomialNB F1-score macro: 0.6642\n",
            "    - ComplementNB F1-score macro: 0.6921\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 1.0}\n",
            "    - MultinomialNB F1-score macro: 0.6530\n",
            "    - ComplementNB F1-score macro: 0.6916\n",
            "Probando parámetros del vectorizador: {'max_df': 0.98, 'min_df': 3, 'ngram_range': (1, 2)}\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 0.1}\n",
            "    - MultinomialNB F1-score macro: 0.6802\n",
            "    - ComplementNB F1-score macro: 0.6961\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 0.5}\n",
            "    - MultinomialNB F1-score macro: 0.6616\n",
            "    - ComplementNB F1-score macro: 0.7026\n",
            "  Probando parámetros del mdelo Naïve Bayes: {'alpha': 1.0}\n",
            "    - MultinomialNB F1-score macro: 0.6512\n",
            "    - ComplementNB F1-score macro: 0.6999\n",
            "==================================================\n",
            "Mejor F1-score macro obtenido: 0.7101\n",
            "Mejores parámetros del vectorizador: {'max_df': 0.95, 'min_df': 2, 'ngram_range': (1, 2)}\n",
            "Mejores parámetros del modelo: {'alpha': 0.5}\n",
            "Mejor modelo: ComplementNB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3378a91e"
      },
      "source": [
        "##**Datos de los Modelos Naïve Bayes**\n",
        "\n",
        "Para entrenar modelos de clasificación Naïve Bayes y maximizar su desempeño (medido por el F1-score macro) en el conjunto de datos de test, se realizó una búsqueda de hiperparámetros explorando diferentes configuraciones para el `TfidfVectorizer` y los modelos `MultinomialNB` y `ComplementNB`.\n",
        "\n",
        "Los parámetros explorados para el `TfidfVectorizer` fueron:\n",
        "*   `max_df`: [0.95, 0.98] (ignorar términos que aparecen en una proporción mayor a este umbral)\n",
        "*   `min_df`: [2, 3] (ignorar términos que aparecen en una proporción menor a este umbral)\n",
        "*   `ngram_range`: [(1, 1), (1, 2)] (considerar unigramas o unigramas y bigramas)\n",
        "*   `stop_words='english'`: Se eliminaron las stop words comunes en inglés.\n",
        "\n",
        "Para los modelos Naïve Bayes (`MultinomialNB` y `ComplementNB`), se exploró el parámetro de suavizado de Laplace:\n",
        "*   `alpha`: [0.1, 0.5, 1.0] (valor de suavizado, ayuda a manejar términos desconocidos en el conjunto de prueba)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Análisis de los resultados:**\n",
        "\n",
        "Cito: **Mejor F1-score macro obtenido: 0.7101**\n",
        "\n",
        "Este desempeño óptimo se logró con la siguiente combinación de parámetros:\n",
        "*   **Vectorizer (`TfidfVectorizer`) Parámetros:**\n",
        "    *   `max_df`: 0.95\n",
        "    *   `min_df`: 2\n",
        "    *   `ngram_range`: (1, 2)\n",
        "*   **Modelo Naïve Bayes Parámetros:**\n",
        "    *   `alpha`: 0.5\n",
        "*   **Mejor Modelo:** ComplementNB\n",
        "\n",
        "**Reflexión sobre el mejor desempeño:**\n",
        "\n",
        "El hecho de que la mejor puntuación se alcanzara con `ngram_range=(1, 2)` sugiere que incluir bigramas (pares de palabras) en la vectorización, además de unigramas (palabras individuales), fue beneficioso. Los bigramas pueden capturar información contextual valiosa que las palabras individuales no siempre proporcionan por sí solas, como frases comunes o términos técnicos específicos de ciertos grupos de noticias (por ejemplo, \"operative system\", \"motorcycle parts\").\n",
        "\n",
        "Los parámetros `max_df=0.95` y `min_df=2` para el vectorizador son razonables. Excluir términos extremadamente comunes (presentes en más del 95% de los documentos) ayuda a eliminar palabras que probablemente no sean discriminatorias entre clases, mientras que excluir términos muy raros (presentes en menos de 2 documentos) ayuda a reducir el ruido y la dimensionalidad, y a manejar mejor los posibles errores tipográficos existentes.\n",
        "\n",
        "El uso de `alpha=0.5` para el suavizado de Laplace indica que aplicar un suavizado moderado fue efectivo. El suavizado de Laplace es crucial en Naïve Bayes para evitar que las probabilidades de las clases se vuelvan cero cuando un término del conjunto de prueba no aparece en el conjunto de entrenamiento. Un valor de 0.5 parece haber funcionado mejor que 0.1 o 1.0 en este caso particular.\n",
        "\n"
      ],
      "metadata": {
        "id": "JA0aFFzeEzGG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Conclusión:**\n",
        "\n",
        "Finalmente, el modelo **ComplementNB** obtuvo el mejor rendimiento general en comparación con MultinomialNB. ComplementNB a menudo funciona mejor que MultinomialNB en conjuntos de datos con clases desequilibradas, ya que se centra en el complemento de cada clase. Esto sugiere que, a pesar de tener 20 clases, puede haber cierto grado de desequilibrio en la distribución de documentos entre los grupos de noticias en este dataset, lo que favoreció el enfoque de ComplementNB.\n",
        "\n",
        "La combinación ganadora de un vectorizador que considera unigramas y bigramas con un manejo adecuado de términos frecuentes/raros, junto con un suavizado de Laplace óptimo en el modelo ComplementNB, permitió alcanzar el mejor rendimiento de clasificación para este dataset."
      ],
      "metadata": {
        "id": "FnSqQl1eFUNf"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}